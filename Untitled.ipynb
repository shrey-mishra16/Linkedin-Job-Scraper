{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas selenium textract scikit-learn spacy nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4694901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import textract # Library to read PDFs\n",
    "import time # PreInstalled library to add sleeping times\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "all_stopwords = stopwords.words('english')\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61da01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "all_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Chromedriver from: https://chromedriver.chromium.org/downloads\n",
    "#Create browser instance by giving the address to chrome webdriver\n",
    "browser = webdriver.Chrome('chromedriver')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6022b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw= [word for word in text_tokens if not word in all_stopwords]\n",
    "    text = ' '.join(tokens_without_sw)\n",
    "    return text\n",
    "\n",
    "def resumeReader(pdf):\n",
    "    # Read Resume\n",
    "    with open(pdf, \"rb\") as pdf_file:\n",
    "        resume = textract.process(pdf).decode(\"utf-8\").replace('\\n',' ')\n",
    "    return resume\n",
    "\n",
    "def score(resume,jobDescription):\n",
    "    cv = CountVectorizer()\n",
    "    resume = ' '.join(set(cleanText(resume).split(' ')))\n",
    "    jobDescription = ' '.join(set(cleanText(jobDescription).split(' ')))\n",
    "    text = [resume,jobDescription]\n",
    "    count_matrix = cv.fit_transform(text)\n",
    "    return round(cosine_similarity(count_matrix)[0][1],2)\n",
    "def getJobInfo(browser):\n",
    "    title = ''\n",
    "    company = ''\n",
    "    companyLink = ''\n",
    "    location = ''\n",
    "    jobLink = ''\n",
    "    posterName = ''\n",
    "    posterProfileLink = ''\n",
    "    jobDescription = ''\n",
    "    try:\n",
    "        title = browser.find_element(By.CLASS_NAME,'jobs-unified-top-card__content--two-pane').text.split('\\n')[0]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        company = browser.find_element(By.CLASS_NAME,'jobs-unified-top-card__company-name').text\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        companyLink = browser.find_element(By.CLASS_NAME,'jobs-unified-top-card__company-name').find_element(By.TAG_NAME,'a').get_attribute('href')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        location = browser.find_element(By.CLASS_NAME,'jobs-unified-top-card__bullet').text\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        jobLink = browser.find_element(By.CLASS_NAME,'jobs-unified-top-card__content--two-pane').find_element(By.TAG_NAME,'a').get_attribute('href')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        posterName = browser.find_element(By.CLASS_NAME,'jobs-poster__name').text\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        posterProfileLink = browser.find_element(By.CLASS_NAME,'jobs-poster__name-link').get_attribute('href')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        jobDescription = browser.find_element(By.CLASS_NAME,'jobs-box__html-content').find_element(By.TAG_NAME,'span').text.replace('\\n',' ')\n",
    "    except:\n",
    "        pass\n",
    "    return [title,company,companyLink,location,jobLink,posterName,posterProfileLink,jobDescription]\n",
    "\n",
    "def loginLinkedIn(browser,usr,psw):\n",
    "    # Go to LinkedIn Login page\n",
    "    browser.get('https://www.linkedin.com/login')\n",
    "    time.sleep(4)\n",
    "    browser.find_element(By.ID,'username').send_keys(usr)\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.ID,'password').send_keys(psw)\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.CLASS_NAME,'btn__primary--large').click()\n",
    "    return browser\n",
    "\n",
    "\n",
    "\n",
    "def getLinkedinJobs(browser,keyword,JT,maxPageNumSearch,Exp,loc):\n",
    "    actions = ActionChains(browser)\n",
    "    loc = keyword.replace(' ','%20')\n",
    "    keyword = keyword.replace(' ','%20') # %20 = space\n",
    "    JT = JT[0].capitalize()\n",
    "    jobData = [['title','company','companyLink','location','jobLink','posterName','posterProfileLink','jobDescription']]\n",
    "    for p in range(maxPageNumSearch):\n",
    "        page = str(p*25)\n",
    "        #print(page)\n",
    "        browser.get('https://www.linkedin.com/jobs/search/?currentJobId=3486556513&f_E='+Exp+'&f_F=eng%2Csale%2Canls%2Cmgmt%2Cfin%2Cit%2Cbd&f_JT='+JT+'&geoId=103644278&keywords='+keyword+'&location='+loc+'&refresh=true&sortBy=R')\n",
    "        time.sleep(3)\n",
    "        #Search for all job postings shown\n",
    "        jobs = browser.find_elements(By.CLASS_NAME,'jobs-search-results__list-item')\n",
    "        i=0\n",
    "        for j in jobs:\n",
    "            #print(i)\n",
    "            i+=1\n",
    "            time.sleep(2)\n",
    "            actions.move_to_element(j).perform()\n",
    "            j.find_element(By.TAG_NAME,'img').click() #Click on the image so it doesnt misclick a URL\n",
    "            jobData.append(getJobInfo(browser))\n",
    "    df = pd.DataFrame(jobData[1:],columns=jobData[0])\n",
    "    #Drop any duplicate\n",
    "    df.drop_duplicates(subset = ['jobLink'],inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da07deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = loginLinkedIn(browser,'shreymmishra16@gmail.com','MP20$r8964')\n",
    "\"\"\"\n",
    "1.Internship\n",
    "2.Entry level\n",
    "3.Associate\n",
    "4.Mid-Senior level\n",
    "5.Director\n",
    "6.Executive\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "F-Full-time\n",
    "P-Part-time\n",
    "C-Contract\n",
    "T-Temporary\n",
    "I-Internship\n",
    "O-Other\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3846b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getLinkedinJobs(browser,'business analyst','internship',40,'1','United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f504e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac88ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
