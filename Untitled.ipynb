{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7a4aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: selenium in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (4.8.2)\n",
      "Collecting textract\n",
      "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: scikit-learn in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (0.24.2)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.5.0-cp39-cp39-macosx_10_9_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.7)\n",
      "Collecting beautifulsoup4~=4.8.0\n",
      "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 23.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting SpeechRecognition~=3.8.1\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 32.8 MB 76 kB/s eta 0:00:0111\n",
      "\u001b[?25hCollecting extract-msg<=0.29.*\n",
      "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 14.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet==3.*\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xlrd~=1.2.0\n",
      "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 14.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docx2txt~=0.8\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "Collecting six~=1.12.0\n",
      "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting python-pptx~=0.6.18\n",
      "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting argcomplete~=1.10.0\n",
      "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting pdfminer.six==20191110\n",
      "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 11.6 MB/s eta 0:00:01     |████▏                           | 727 kB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycryptodome\n",
      "  Downloading pycryptodome-3.17-cp35-abi3-macosx_10_9_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sortedcontainers in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-macosx_10_9_x86_64.whl (32 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.8-cp39-cp39-macosx_10_9_x86_64.whl (865 kB)\n",
      "\u001b[K     |████████████████████████████████| 865 kB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: jinja2 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.11.3)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-macosx_10_9_x86_64.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 18.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 8.4 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp39-cp39-macosx_10_9_x86_64.whl (492 kB)\n",
      "\u001b[K     |████████████████████████████████| 492 kB 16.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-macosx_10_9_x86_64.whl (18 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy) (21.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 21.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.5-cp39-cp39-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 18.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4~=4.8.0->textract) (2.2.1)\n",
      "Collecting imapclient==2.1.0\n",
      "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting compressed-rtf>=1.0.6\n",
      "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
      "Collecting ebcdic>=1.1.1\n",
      "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: olefile>=0.46 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from extract-msg<=0.29.*->textract) (0.46)\n",
      "Collecting tzlocal>=2.1\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from python-pptx~=0.6.18->textract) (4.6.3)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from python-pptx~=0.6.18->textract) (8.4.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from python-pptx~=0.6.18->textract) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp39-cp39-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.1 MB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: async-generator>=1.9 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: outcome in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.7-py2.py3-none-any.whl (340 kB)\n",
      "\u001b[K     |████████████████████████████████| 340 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, python-pptx\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=d84edb1fdc556392242f273e0c126c64e0680cb50d9587d82099b35e412ce6f3\n",
      "  Stored in directory: /Users/shrey/Library/Caches/pip/wheels/40/75/01/e6c444034338bde9c7947d3467807f889123465c2371e77418\n",
      "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6200 sha256=e7f906e21c0fe1325969631fa73343dbdf6696115108fd74f900e150d3c23b78\n",
      "  Stored in directory: /Users/shrey/Library/Caches/pip/wheels/e4/67/e4/ba2159853bdd0fe99330aa1e384915108143a5370686ea446f\n",
      "  Building wheel for python-pptx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470950 sha256=5b741c1c57bb10f7097e8da185fcc1d08cbcf19e933f0bf8f9c8d5388a2c7f52\n",
      "  Stored in directory: /Users/shrey/Library/Caches/pip/wheels/0e/4a/ed/9653bc799915f52dce3f04d14946fbd85cce9c3cdedc9cfa71\n",
      "Successfully built docx2txt compressed-rtf python-pptx\n",
      "Installing collected packages: tzdata, typing-extensions, catalogue, srsly, six, pytz-deprecation-shim, pydantic, murmurhash, cymem, wasabi, tzlocal, typer, smart-open, pycryptodome, preshed, imapclient, ebcdic, confection, compressed-rtf, chardet, blis, xlrd, thinc, SpeechRecognition, spacy-loggers, spacy-legacy, python-pptx, pdfminer.six, pathy, langcodes, extract-msg, docx2txt, beautifulsoup4, argcomplete, textract, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: xlrd\n",
      "    Found existing installation: xlrd 2.0.1\n",
      "    Uninstalling xlrd-2.0.1:\n",
      "      Successfully uninstalled xlrd-2.0.1\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.10.0\n",
      "    Uninstalling beautifulsoup4-4.10.0:\n",
      "      Successfully uninstalled beautifulsoup4-4.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\u001b[0m\n",
      "Successfully installed SpeechRecognition-3.8.1 argcomplete-1.10.3 beautifulsoup4-4.8.2 blis-0.7.9 catalogue-2.0.8 chardet-3.0.4 compressed-rtf-1.0.6 confection-0.0.4 cymem-2.0.7 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 pdfminer.six-20191110 preshed-3.0.8 pycryptodome-3.17 pydantic-1.10.5 python-pptx-0.6.21 pytz-deprecation-shim-0.1.0.post0 six-1.12.0 smart-open-6.3.0 spacy-3.5.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 textract-1.6.5 thinc-8.1.8 typer-0.7.0 typing-extensions-4.5.0 tzdata-2022.7 tzlocal-4.2 wasabi-1.1.1 xlrd-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas selenium textract scikit-learn spacy nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5551651f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 17.1 MB/s eta 0:00:01   |███▌                            | 1.4 MB 266 kB/s eta 0:00:43\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.26.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.20.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.62.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (58.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/shrey/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4694901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import textract # Library to read PDFs\n",
    "import time # PreInstalled library to add sleeping times\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "all_stopwords = stopwords.words('english')\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61da01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83e9ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/shrey/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6880428e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/shrey/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /Users/shrey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "all_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70a8f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Chromedriver from: https://chromedriver.chromium.org/downloads\n",
    "#Create browser instance by giving the address to chrome webdriver\n",
    "browser = webdriver.Chrome('chromedriver')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6022b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw= [word for word in text_tokens if not word in all_stopwords]\n",
    "    text = ' '.join(tokens_without_sw)\n",
    "    return text\n",
    "\n",
    "def resumeReader(pdf):\n",
    "    # Read Resume\n",
    "    with open(pdf, \"rb\") as pdf_file:\n",
    "        resume = textract.process(pdf).decode(\"utf-8\").replace('\\n',' ')\n",
    "    return resume\n",
    "\n",
    "def score(resume,jobDescription):\n",
    "    cv = CountVectorizer()\n",
    "    resume = ' '.join(set(cleanText(resume).split(' ')))\n",
    "    jobDescription = ' '.join(set(cleanText(jobDescription).split(' ')))\n",
    "    text = [resume,jobDescription]\n",
    "    count_matrix = cv.fit_transform(text)\n",
    "    return round(cosine_similarity(count_matrix)[0][1],2)\n",
    "def getJobInfo(browser):\n",
    "    title = ''\n",
    "    company = ''\n",
    "    companyLink = ''\n",
    "    location = ''\n",
    "    jobLink = ''\n",
    "    posterName = ''\n",
    "    posterProfileLink = ''\n",
    "    jobDescription = ''\n",
    "    try:\n",
    "        title = browser.find_element(By.CLASS_NAME,'jobs-unified-top-card__content--two-pane').text.split('\\n')[0]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        company = browser.find_element(By.CLASS_NAME,'jobs-unified-top-card__company-name').text\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        companyLink = browser.find_element(By.CLASS_NAME,'jobs-unified-top-card__company-name').find_element(By.TAG_NAME,'a').get_attribute('href')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        location = browser.find_element(By.CLASS_NAME,'jobs-unified-top-card__bullet').text\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        jobLink = browser.find_element(By.CLASS_NAME,'jobs-unified-top-card__content--two-pane').find_element(By.TAG_NAME,'a').get_attribute('href')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        posterName = browser.find_element(By.CLASS_NAME,'jobs-poster__name').text\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        posterProfileLink = browser.find_element(By.CLASS_NAME,'jobs-poster__name-link').get_attribute('href')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        jobDescription = browser.find_element(By.CLASS_NAME,'jobs-box__html-content').find_element(By.TAG_NAME,'span').text.replace('\\n',' ')\n",
    "    except:\n",
    "        pass\n",
    "    return [title,company,companyLink,location,jobLink,posterName,posterProfileLink,jobDescription]\n",
    "\n",
    "def loginLinkedIn(browser,usr,psw):\n",
    "    # Go to LinkedIn Login page\n",
    "    browser.get('https://www.linkedin.com/login')\n",
    "    time.sleep(4)\n",
    "    browser.find_element(By.ID,'username').send_keys(usr)\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.ID,'password').send_keys(psw)\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.CLASS_NAME,'btn__primary--large').click()\n",
    "    return browser\n",
    "\n",
    "\n",
    "\n",
    "def getLinkedinJobs(browser,keyword,JT,maxPageNumSearch,Exp,loc):\n",
    "    actions = ActionChains(browser)\n",
    "    loc = keyword.replace(' ','%20')\n",
    "    keyword = keyword.replace(' ','%20') # %20 = space\n",
    "    JT = JT[0].capitalize()\n",
    "    jobData = [['title','company','companyLink','location','jobLink','posterName','posterProfileLink','jobDescription']]\n",
    "    for p in range(maxPageNumSearch):\n",
    "        page = str(p*25)\n",
    "        #print(page)\n",
    "        browser.get('https://www.linkedin.com/jobs/search/?currentJobId=3486556513&f_E='+Exp+'&f_F=eng%2Csale%2Canls%2Cmgmt%2Cfin%2Cit%2Cbd&f_JT='+JT+'&geoId=103644278&keywords='+keyword+'&location='+loc+'&refresh=true&sortBy=R')\n",
    "        time.sleep(3)\n",
    "        #Search for all job postings shown\n",
    "        jobs = browser.find_elements(By.CLASS_NAME,'jobs-search-results__list-item')\n",
    "        i=0\n",
    "        for j in jobs:\n",
    "            #print(i)\n",
    "            i+=1\n",
    "            time.sleep(2)\n",
    "            actions.move_to_element(j).perform()\n",
    "            j.find_element(By.TAG_NAME,'img').click() #Click on the image so it doesnt misclick a URL\n",
    "            jobData.append(getJobInfo(browser))\n",
    "    df = pd.DataFrame(jobData[1:],columns=jobData[0])\n",
    "    #Drop any duplicate\n",
    "    df.drop_duplicates(subset = ['jobLink'],inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da07deaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nF-Full-time\\nP-Part-time\\nC-Contract\\nT-Temporary\\nI-Internship\\nO-Other'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser = loginLinkedIn(browser,'shreymmishra16@gmail.com','MP20$r8964')\n",
    "\"\"\"\n",
    "1.Internship\n",
    "2.Entry level\n",
    "3.Associate\n",
    "4.Mid-Senior level\n",
    "5.Director\n",
    "6.Executive\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "F-Full-time\n",
    "P-Part-time\n",
    "C-Contract\n",
    "T-Temporary\n",
    "I-Internship\n",
    "O-Other\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3846b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bj/z11j3wrn15928lxs5dh4pbt40000gn/T/ipykernel_86654/4263718255.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLinkedinJobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'business analyst'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'internship'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'United States'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/bj/z11j3wrn15928lxs5dh4pbt40000gn/T/ipykernel_86654/4076344707.py\u001b[0m in \u001b[0;36mgetLinkedinJobs\u001b[0;34m(browser, keyword, JT, maxPageNumSearch, Exp, loc)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTAG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Click on the image so it doesnt misclick a URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = getLinkedinJobs(browser,'business analyst','internship',40,'1','United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56f504e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bj/z11j3wrn15928lxs5dh4pbt40000gn/T/ipykernel_86654/223627333.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac88ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
